import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt

# Split the data into training and testing sets
train_size = int(len(df) * 0.8)
train_data = df.iloc[:train_size,:]
test_data = df.iloc[train_size:,:]

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
train_data_scaled = scaler.fit_transform(train_data[['PM2.5']])
test_data_scaled = scaler.transform(test_data[['PM2.5']])

# Convert the data into sequences
def create_sequences(data, seq_length):
    X = []
    y = []
    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i])
        y.append(data[i])
    X = np.array(X)
    y = np.array(y)
    return X, y

seq_length = 3
X_train, y_train = create_sequences(train_data_scaled, seq_length)
X_test, y_test = create_sequences(test_data_scaled, seq_length)

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Make predictions on the test set
y_pred = model.predict(X_test)
y_pred = scaler.inverse_transform(y_pred)
y_test = scaler.inverse_transform(y_test)

# Print the MSE and R-squared values for the training and testing sets
#print('MSE train:', mean_squared_error(y_train, y_train_pred))
print('MSE test:', mean_squared_error(y_test, y_pred))
#print('R^2 train:', r2_score(y_train, y_train_pred))
print('R^2 test:', r2_score(y_test, y_pred))

# Plot the results
plt.plot(train_data['PM2.5'])
plt.plot(range(train_size, len(df)), test_data['PM2.5'])
plt.plot(range(train_size+seq_length, len(df)), y_pred)
plt.ylabel('PM2.5')
plt.legend(['Train', 'Test', 'Predictions'])
plt.show()